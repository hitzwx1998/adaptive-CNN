import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.metrics import classification_report
# gpu计算用的
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession
config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

# 读取风机叶片结冰数据15 包括正常数据，故障数据以及标签
# 读取后是DataFrame格式
# 训练数据
train_x_normal_dataframe = pd.read_csv('train_x_normal.csv')
label_y_normal_dataframe = pd.read_csv('label_y_normal.csv')
train_x_failure_dataframe = pd.read_csv('train_x_failure.csv')
label_y_failure_dataframe = pd.read_csv('label_y_failure.csv')

# 测试数据
test_x_dataframe = pd.read_csv('test_x.csv')
test_y_dataframe = pd.read_csv('test_y.csv')


# 将DataFrame格式转换为numpy格式
# 训练数据
train_x_normal = train_x_normal_dataframe.values[:,1:]
train_x_failure = train_x_failure_dataframe.values[:,1:]
label_y_normal = label_y_normal_dataframe.values[:,1:]
label_y_failure = label_y_failure_dataframe.values[:,1:]

# 测试数据
test_x = test_x_dataframe.values[:,1:]
test_y = test_y_dataframe.values[:,1:]


# 输出各个数据的维度
print(train_x_normal.shape,label_y_normal.shape,train_x_failure.shape,label_y_normal.shape)
# 正常数据和故障数据比例大约为15：1，属于不平衡分类问题。
# 需要对正常数据进行欠采样，对故障数据进行过采样


# 对正常数据进行欠采样
# 欠采样分数
T1 = 5
# 欠采样之后的数据个数
size = int(train_x_normal.shape[0] / T1)
# 取size大小的正常数据，以及正常数据的标签
train_x_normal = train_x_normal[:size,:]
label_y_normal = label_y_normal[:size,:]

# 对故障数据进行过采样
# 利用python中的包 smote()



# 正常数据、故障数据拼接  正常标签，故障标签拼接   其中正常数据已经进行欠采样
# train_x : [samples,106*26]
# train_y : [samples,1]
train_x = np.r_[train_x_normal,train_x_failure]
train_y = np.r_[label_y_normal,label_y_failure]

# 调用模型
smote_model = SMOTE()
# 进行过采样处理
train_x_smote,train_y_smote = smote_model.fit_sample(train_x,train_y)

train_y_smote = np.reshape(train_y_smote,newshape=(train_y_smote.shape[0],1))
# 输出过采样后数据的维度
print('----------过采样之后的数据维度----------')
print(train_x_smote.shape,train_y_smote.shape)

# 将特征值和目标值组合成一个DataFrame
#smote_df = pd.concat([train_x_smote,train_y_smote],axis=1)
#print('----------查看分布情况----------')
#print(smote_df.groupby('label').count())

# 实现测试数据平衡
test_x_normal = test_x[:1000,:]
test_y_normal = test_y[:1000,:]
test_x_failure = test_x[-600:,:]
test_y_failure = test_y[-600:,:]

test_x = np.r_[test_x_normal,test_x_failure]
test_y = np.r_[test_y_normal,test_y_failure]

# 数据归一化
scaler = StandardScaler()
train_x = scaler.fit_transform(train_x_smote)
test_x = scaler.transform(test_x)

train_y = train_y_smote
# 调整输入数据形状
# train_x : [samples,106*26] => [samples,106,26]
train_x = np.reshape(train_x,newshape=(train_x.shape[0],106,26))
test_x = np.reshape(test_x,newshape=(test_x.shape[0],106,26))

# 打印
print('----------训练集数据形状----------')
print(train_x.shape,train_y.shape)
print('----------测试数据集形状----------')
print(test_x.shape,test_y.shape)


class my_activation_layer(tf.keras.layers.Layer):
    def __init__(self):
        super().__init__()

    def build(self, input_shape):
        self.alpha = self.add_weight(name='alpha', shape=[1], initializer=tf.random_normal_initializer())
        self.belta = self.add_weight(name='belta', shape=[1], initializer=tf.random_normal_initializer())
        self.lembda = self.add_weight(name='lambda', shape=[1], initializer=tf.random_normal_initializer())

    def call(self, inputs, **kwargs):
        y_elu = tf.nn.elu(inputs)
        y_sigmoid = tf.nn.sigmoid(inputs)
        y_prelu_pos = tf.nn.relu(inputs)
        y_prelu_neg = self.lembda * (inputs - tf.abs(inputs)) * 0.5
        y_prelu = y_prelu_pos + y_prelu_neg
        y_pred = self.alpha * y_elu + self.belta * y_prelu + (1 - self.alpha - self.belta) * y_sigmoid
        return y_pred

print('----------cnn+LSTM----------')
CLSTM_model = tf.keras.Sequential()
CLSTM_model.add(tf.keras.layers.Conv1D(filters=32,kernel_size=10,strides=2))
CLSTM_model.add(my_activation_layer())
CLSTM_model.add(tf.keras.layers.MaxPool1D(pool_size=2))
CLSTM_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100,activation='relu',return_sequences=True)))
CLSTM_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50,activation='relu')))
CLSTM_model.add(tf.keras.layers.Dropout(0.5))
CLSTM_model.add(tf.keras.layers.Dense(64,activation='relu'))


CLSTM_model.add(tf.keras.layers.Dropout(0.5))
CLSTM_model.add(tf.keras.layers.Dense(32,activation='relu'))
CLSTM_model.add(tf.keras.layers.Dense(2,activation='softmax'))

# 模型提纲
CLSTM_model.build(input_shape=(None,106,26))
CLSTM_model.summary()

# 初始化任一输出
x = tf.random.uniform(shape=(1,106,26))
for layer in CLSTM_model.layers:
    x = layer(x)
    print(layer.name,'output.shape\t',x.shape)

# 模型编译
CLSTM_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),
                    loss='sparse_categorical_crossentropy',
                    metrics=['accuracy'])

# 模型训练
training_CLSTM = CLSTM_model.fit(train_x,train_y,batch_size=128,epochs=20)

# 画出训练过程中的损失
plt.plot(training_CLSTM.history['loss'],label='Linear Combination CNN-BLSTM train')
#plt.plot(training_CLSTM.history['val_loss'],label='Linear Combination CNN-BLSTM test')


print('----------模型评估----------')
CLSTM_model.evaluate(test_x,test_y)

predict_y = CLSTM_model.predict(test_x)
print('----------模型对测试集的预测输出的维度----------')
print(predict_y.shape)
print('----------模型对测试集的预测的输出的前5行----------')
print(predict_y[:5,:])

# 生成判断类别结果
predict_y_result = np.zeros(shape=[predict_y.shape[0],1])
for i in range(predict_y.shape[0]):
    if predict_y[i][0] > predict_y[i][1]:
        predict_y_result[i,0] = 0
    else:
        predict_y_result[i,0] = 1
# 打印结果维度
print(predict_y_result.shape,test_y.shape)
# 打印分类报告
print('----------分类报告----------')
print(classification_report(test_y,predict_y_result))





class my_adaptive_activation(tf.keras.layers.Layer):
    def __init__(self):
        super().__init__()

    def build(self, input_shape):
        self.lembda = self.add_weight(name='lambda', shape=[1], initializer=tf.random_normal_initializer())
        self.lembda1 = self.add_weight(name='lambda1',shape=[input_shape[-1],input_shape[-1]],initializer=tf.random_normal_initializer())
        self.lembda2 = self.add_weight(name='lambda2',shape=[input_shape[-1],input_shape[-1]],initializer=tf.random_normal_initializer())
    def call(self, inputs, **kwargs):
        y_elu = tf.nn.elu(inputs)
        y_sigmoid = tf.nn.sigmoid(inputs)
        y_prelu_pos = tf.nn.relu(inputs)
        y_prelu_neg = self.lembda * (inputs - tf.abs(inputs)) * 0.5
        y_prelu = y_prelu_pos + y_prelu_neg

        y_sigmoid_1 = 1 / (1 + tf.exp(-1 * tf.matmul(inputs,self.lembda1)))
        y_sigmoid_2 = 1 / (1 + tf.exp(-1 * tf.matmul(inputs,self.lembda2)))



        y_pred = y_sigmoid_1 * y_elu + y_sigmoid_2 * y_prelu + (1 - y_sigmoid_1 - y_sigmoid_2) * y_sigmoid

        return y_pred

print('----------使用门控自适应cnn+LSTM----------')
cnn_LSTM_model = tf.keras.Sequential()
cnn_LSTM_model.add(tf.keras.layers.Conv1D(filters=32,kernel_size=10,strides=2))
cnn_LSTM_model.add(my_adaptive_activation())
#cnn_LSTM_model.add(tf.keras.layers.Conv1D(filters=64,kernel_size=10))
#cnn_LSTM_model.add(my_adaptive_activation())
cnn_LSTM_model.add(tf.keras.layers.MaxPool1D(pool_size=2))
cnn_LSTM_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100,activation='relu',return_sequences=True)))
cnn_LSTM_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50,activation='relu')))
cnn_LSTM_model.add(tf.keras.layers.Dropout(0.5))
cnn_LSTM_model.add(tf.keras.layers.Dense(64,activation='relu'))
cnn_LSTM_model.add(tf.keras.layers.Dropout(0.5))
cnn_LSTM_model.add(tf.keras.layers.Dense(32,activation='relu'))
cnn_LSTM_model.add(tf.keras.layers.Dense(2,activation='softmax'))

# 模型提纲
cnn_LSTM_model.build(input_shape=(None,106,26))
cnn_LSTM_model.summary()

# 初始化任一输入
x = tf.random.uniform(shape=(1,106,26))
for layer in cnn_LSTM_model.layers:
    x = layer(x)
    print(layer.name,'output.shape\t',x.shape)

# 模型编译
cnn_LSTM_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),
                       loss='sparse_categorical_crossentropy',
                       metrics=['accuracy'])

# 模型训练
training_cnn_LSTM = cnn_LSTM_model.fit(train_x,train_y,batch_size=128,epochs=20)

# 画出训练过程中的损失
plt.plot(training_cnn_LSTM.history['loss'],label='Gated Adaptive CNN-BLSTM train')
#plt.plot(training_cnn_LSTM.history['val_loss'],label='Gated Adaptive test')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.title('The Training of Adaptive CNN-BLSTM')
plt.legend()
plt.show()
